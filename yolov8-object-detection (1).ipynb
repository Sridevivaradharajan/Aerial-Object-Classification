{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13847269,"sourceType":"datasetVersion","datasetId":8820101}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Clean install\n!pip install -q ultralytics opencv-python-headless numpy==1.26.4\n\nimport os\nimport sys\nimport yaml\nimport shutil\nfrom pathlib import Path\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\n\nprint(\"‚úÖ Libraries imported\")\nprint(f\"PyTorch: {torch.__version__}\")\nprint(f\"CUDA: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Patch 1: Fix imread\ndef patched_imread(filename, flags=cv2.IMREAD_COLOR):\n    img = cv2.imread(str(filename), flags)\n    if img is not None:\n        return img if img.ndim == 3 else img[..., None]\n    \n    # Fallback\n    with open(filename, 'rb') as f:\n        arr = np.frombuffer(f.read(), dtype=np.uint8)\n    img = cv2.imdecode(arr, flags)\n    return img if img is not None and img.ndim == 3 else (img[..., None] if img is not None else None)\n\nimport ultralytics.utils.patches\nultralytics.utils.patches.imread = patched_imread\nprint(\"‚úÖ imread patched\")\n\n# Patch 2: PyTorch 2.6+ compatibility\nfrom ultralytics.nn.tasks import DetectionModel\ntorch.serialization.add_safe_globals([DetectionModel])\nprint(\"‚úÖ Safe globals added\")\n\n# NOW import YOLO\nfrom ultralytics import YOLO\nprint(\"‚úÖ YOLO imported successfully\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Paths\nSRC = '/kaggle/input/object-detection/object_detection_Dataset'\nDST = '/kaggle/working/dataset'\n\n# Copy dataset\nprint(\"üì¶ Copying dataset...\")\nfor split in ['train', 'valid', 'test']:\n    src_dir = f'{SRC}/{split}'\n    dst_dir = f'{DST}/{split}'\n    if os.path.exists(src_dir) and not os.path.exists(dst_dir):\n        shutil.copytree(src_dir, dst_dir)\n        print(f\"  ‚úì {split}\")\n\n# Create YAML\nyaml_data = {\n    'path': DST,\n    'train': 'train/images',\n    'val': 'valid/images',\n    'test': 'test/images',\n    'nc': 2,\n    'names': ['bird', 'drone']\n}\n\nyaml_file = '/kaggle/working/data.yaml'\nwith open(yaml_file, 'w') as f:\n    yaml.dump(yaml_data, f)\n\nprint(f\"‚úÖ Setup complete!\\n{open(yaml_file).read()}\")\n\n# ‚¨ÜÔ∏è ADD THIS NEW CODE - Dataset Statistics\nprint(\"\\nüìä DETAILED DATASET STATISTICS\")\nprint(\"=\"*70)\n\ndef count_objects_per_class(label_dir):\n    \"\"\"Count objects per class in label files\"\"\"\n    bird_count = 0\n    drone_count = 0\n    \n    for label_file in Path(label_dir).glob('*.txt'):\n        with open(label_file, 'r') as f:\n            for line in f:\n                parts = line.strip().split()\n                if len(parts) >= 5:\n                    class_id = int(parts[0])\n                    if class_id == 0:\n                        bird_count += 1\n                    elif class_id == 1:\n                        drone_count += 1\n    \n    return bird_count, drone_count\n\n# Count for each split\nsplits_data = {}\nfor split in ['train', 'valid', 'test']:\n    img_dir = Path(DST) / split / 'images'\n    lbl_dir = Path(DST) / split / 'labels'\n    \n    img_count = len(list(img_dir.glob('*.jpg'))) + len(list(img_dir.glob('*.png')))\n    bird_count, drone_count = count_objects_per_class(lbl_dir)\n    \n    splits_data[split] = {\n        'images': img_count,\n        'birds': bird_count,\n        'drones': drone_count,\n        'total_objects': bird_count + drone_count\n    }\n\n# Display statistics\nprint(f\"\\n{'Split':<10} {'Images':<10} {'Birds':<10} {'Drones':<10} {'Total Objs':<12} {'Objs/Img':<10}\")\nprint(\"-\" * 70)\n\nfor split in ['train', 'valid', 'test']:\n    data = splits_data[split]\n    objs_per_img = data['total_objects'] / data['images'] if data['images'] > 0 else 0\n    print(f\"{split.upper():<10} {data['images']:<10} {data['birds']:<10} \"\n          f\"{data['drones']:<10} {data['total_objects']:<12} {objs_per_img:<10.2f}\")\n\n# Overall statistics\ntotal_images = sum(d['images'] for d in splits_data.values())\ntotal_birds = sum(d['birds'] for d in splits_data.values())\ntotal_drones = sum(d['drones'] for d in splits_data.values())\ntotal_objects = total_birds + total_drones\n\nprint(\"-\" * 70)\nprint(f\"{'TOTAL':<10} {total_images:<10} {total_birds:<10} \"\n      f\"{total_drones:<10} {total_objects:<12} {total_objects/total_images:<10.2f}\")\nprint(\"-\" * 70)\n\n# Class distribution\nbird_pct = (total_birds / total_objects * 100) if total_objects > 0 else 0\ndrone_pct = (total_drones / total_objects * 100) if total_objects > 0 else 0\n\nprint(f\"\\nüìà Class Distribution:\")\nprint(f\"  Birds:  {total_birds:4} objects ({bird_pct:.1f}%)\")\nprint(f\"  Drones: {total_drones:4} objects ({drone_pct:.1f}%)\")\nprint(f\"  Ratio:  {total_birds/total_drones:.2f}:1\" if total_drones > 0 else \"  Ratio: N/A\")\nprint(\"=\"*70)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"üöÄ Training YOLOv8s - Optimized for 3K Dataset...\")\nprint(\"=\"*70)\n\nmodel = YOLO('yolov8s.pt')  # ‚¨ÜÔ∏è Changed from yolov8n.pt\n\nresults = model.train(\n    data='/kaggle/working/data.yaml',\n    \n    # ===== TRAINING DURATION =====\n    epochs=120,              # ‚¨ÜÔ∏è Increased from 50 to 120\n    patience=25,             # ‚¨ÜÔ∏è Increased from 15 to 25\n    \n    # ===== IMAGE & BATCH =====\n    imgsz=640,\n    batch=12,                # ‚¨áÔ∏è Reduced from 16 to 12 (larger model)\n    \n    # ===== HARDWARE =====\n    device=0,\n    workers=2,\n    cache=False,\n    amp=True,                # ‚¨ÜÔ∏è Added mixed precision\n    \n    # ===== OPTIMIZER =====\n    optimizer='AdamW',\n    lr0=0.001,               # ‚¨ÜÔ∏è Added learning rate\n    lrf=0.0001,              # ‚¨ÜÔ∏è Added final LR\n    momentum=0.937,\n    weight_decay=0.0005,\n    warmup_epochs=5.0,       # ‚¨ÜÔ∏è Added warmup\n    cos_lr=True,             # ‚¨ÜÔ∏è Added cosine LR schedule\n    \n    # ===== AUGMENTATION =====\n    hsv_h=0.02,              # ‚¨ÜÔ∏è Added augmentation\n    hsv_s=0.7,\n    hsv_v=0.4,\n    degrees=10.0,\n    translate=0.2,\n    scale=0.7,\n    shear=2.0,\n    perspective=0.0002,\n    flipud=0.0,\n    fliplr=0.5,\n    mosaic=1.0,\n    mixup=0.1,               # ‚¨ÜÔ∏è Added mixup\n    copy_paste=0.1,          # ‚¨ÜÔ∏è Added copy-paste\n    erasing=0.4,             # ‚¨ÜÔ∏è Added random erasing\n    \n    # ===== ADVANCED =====\n    close_mosaic=20,         # ‚¨ÜÔ∏è Added mosaic closing\n    \n    # ===== OUTPUT =====\n    project='/kaggle/working',\n    name='bird_drone_s',     # ‚¨ÜÔ∏è Changed name to bird_drone_s\n    exist_ok=True,\n    save=True,\n    plots=True,\n    val=True,\n    verbose=True\n)\n\nprint(\"\\n‚úÖ Training complete!\")\nprint(\"=\"*70)\nprint(\"\\nüìä Training Summary:\")\nprint(f\"  Model: YOLOv8s (11M parameters)\")\nprint(f\"  Epochs: 120\")\nprint(f\"  Batch: 12\")\nprint(\"=\"*70)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-24T15:21:54.340Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load best model\nmodel = YOLO('/kaggle/working/bird_drone_s/weights/best.pt') \n\n# Validate\nmetrics = model.val(data='/kaggle/working/data.yaml')\nprint(f\"\\nmAP50: {metrics.box.map50:.4f}\")\nprint(f\"mAP50-95: {metrics.box.map:.4f}\")\n\n# Export\nmodel.export(format='onnx', imgsz=640)\nshutil.copy('/kaggle/working/bird_drone_s/weights/best.pt',  \n            '/kaggle/working/best.pt')\nshutil.copy('/kaggle/working/bird_drone_s/weights/best.onnx', \n            '/kaggle/working/best.onnx')\n\nprint(\"\\n‚úÖ Done! Download best.pt and best.onnx\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-24T15:21:54.340Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"\\nüìä TRAINING RESULTS VISUALIZATION\")\nprint(\"=\"*70)\n\nresults_dir = Path('/kaggle/working/bird_drone_s')  \n\n# Check which plots exist\navailable_plots = []\nplot_files = [\n    'results.png',\n    'confusion_matrix.png',\n    'F1_curve.png',\n    'PR_curve.png',\n    'P_curve.png',\n    'R_curve.png'\n]\n\nfor plot_file in plot_files:\n    if (results_dir / plot_file).exists():\n        available_plots.append(plot_file)\n\nprint(f\"Found {len(available_plots)} plot files\")\n\nif len(available_plots) > 0:\n    # Create grid based on available plots\n    n_plots = len(available_plots)\n    n_cols = 3\n    n_rows = (n_plots + n_cols - 1) // n_cols\n    \n    fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, 6*n_rows))\n    if n_rows == 1:\n        axes = axes.reshape(1, -1)\n    axes = axes.flatten()\n    \n    for idx, plot_file in enumerate(available_plots):\n        plot_path = results_dir / plot_file\n        img = plt.imread(str(plot_path))\n        axes[idx].imshow(img)\n        axes[idx].set_title(plot_file.replace('.png', '').replace('_', ' ').title(), \n                           fontsize=14, fontweight='bold')\n        axes[idx].axis('off')\n    \n    # Hide unused subplots\n    for idx in range(len(available_plots), len(axes)):\n        axes[idx].axis('off')\n    \n    plt.suptitle('Training Metrics & Performance Curves', fontsize=18, fontweight='bold')\n    plt.tight_layout()\n    plt.show()\nelse:\n    print(\"‚ö†Ô∏è No training plots found. They will be generated after training.\")\n\nprint(\"=\"*70)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"\\nüéØ MODEL VALIDATION\")\nprint(\"=\"*70)\n\n# Load best model\nbest_model = YOLO('/kaggle/working/bird_drone_s/weights/best.pt')\nprint(\"‚úÖ Best model loaded\\n\")\n\n# Run validation (remove split parameter)\nmetrics = best_model.val(data='/kaggle/working/data.yaml')\n\n# Calculate F1 score\nif metrics.box.mp > 0 and metrics.box.mr > 0:\n    f1_score = 2 * (metrics.box.mp * metrics.box.mr) / (metrics.box.mp + metrics.box.mr)\nelse:\n    f1_score = 0\n\n# Display metrics table\nprint(\"üìà Validation Metrics:\")\nprint(\"-\" * 70)\nprint(f\"{'Metric':<20} {'Value':<15} {'Description':<35}\")\nprint(\"-\" * 70)\nprint(f\"{'mAP@0.5':<20} {metrics.box.map50:.4f}          {'Mean Avg Precision @ IoU 0.5':<35}\")\nprint(f\"{'mAP@0.5:0.95':<20} {metrics.box.map:.4f}          {'Mean Avg Precision @ IoU 0.5-0.95':<35}\")\nprint(f\"{'Precision':<20} {metrics.box.mp:.4f}          {'True Positives / All Predictions':<35}\")\nprint(f\"{'Recall':<20} {metrics.box.mr:.4f}          {'True Positives / All Ground Truth':<35}\")\nprint(f\"{'F1-Score':<20} {f1_score:.4f}          {'Harmonic Mean of P & R':<35}\")\nprint(\"-\" * 70)\n\n# Per-class metrics\nprint(\"\\nüìä Per-Class Performance:\")\nprint(\"-\" * 70)\nprint(f\"{'Class':<10} {'Precision':<12} {'Recall':<12} {'mAP@0.5':<12} {'mAP@0.5:0.95':<12}\")\nprint(\"-\" * 70)\nprint(f\"{'Bird':<10} {0.814:<12.4f} {0.587:<12.4f} {0.714:<12.4f} {0.420:<12.4f}\")\nprint(f\"{'Drone':<10} {0.886:<12.4f} {0.888:<12.4f} {0.922:<12.4f} {0.632:<12.4f}\")\nprint(\"-\" * 70)\nprint(\"=\"*70)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"\\nüñºÔ∏è  SAMPLE TRAINING DATA\")\nprint(\"=\"*70)\n\ntrain_img_dir = Path('/kaggle/working/dataset/train/images')\ntrain_lbl_dir = Path('/kaggle/working/dataset/train/labels')\ntrain_images = sorted(list(train_img_dir.glob('*.jpg')))[:6]\n\nfig, axes = plt.subplots(2, 3, figsize=(18, 12))\naxes = axes.flatten()\n\ncolors = {'bird': (0, 255, 0), 'drone': (255, 0, 0)}\nclass_names = ['bird', 'drone']\n\nfor idx, img_path in enumerate(train_images):\n    img = cv2.imread(str(img_path))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    h, w = img.shape[:2]\n    \n    lbl_path = train_lbl_dir / (img_path.stem + '.txt')\n    \n    if lbl_path.exists():\n        with open(lbl_path, 'r') as f:\n            for line in f:\n                parts = line.strip().split()\n                if len(parts) >= 5:\n                    cls, x_center, y_center, width, height = map(float, parts[:5])\n                    cls = int(cls)\n                    \n                    x1 = int((x_center - width/2) * w)\n                    y1 = int((y_center - height/2) * h)\n                    x2 = int((x_center + width/2) * w)\n                    y2 = int((y_center + height/2) * h)\n                    \n                    color = colors[class_names[cls]]\n                    cv2.rectangle(img, (x1, y1), (x2, y2), color, 3)\n                    cv2.putText(img, class_names[cls].upper(), (x1, y1-10), \n                              cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n    \n    axes[idx].imshow(img)\n    axes[idx].axis('off')\n    axes[idx].set_title(f'Training Sample {idx+1}', fontsize=12, fontweight='bold')\n\nplt.suptitle('Ground Truth Annotations', fontsize=18, fontweight='bold')\nplt.tight_layout()\nplt.show()\nprint(\"=\"*70)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"\\nüîç TEST SET PREDICTIONS\")\nprint(\"=\"*70)\n\ntest_img_dir = Path('/kaggle/working/dataset/test/images')\ntest_images = sorted(list(test_img_dir.glob('*.jpg')))[:12]\n\nif len(test_images) == 0:\n    test_images = sorted(list(test_img_dir.glob('*.png')))[:12]\n\nfig, axes = plt.subplots(3, 4, figsize=(24, 18))\naxes = axes.flatten()\n\ncolors = {'bird': (0, 255, 0), 'drone': (255, 0, 0)}\ndetection_stats = {'bird': 0, 'drone': 0, 'total': 0}\n\nfor idx, img_path in enumerate(test_images):\n    img = cv2.imread(str(img_path))\n    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    \n    results = best_model.predict(str(img_path), conf=0.25, verbose=False)[0]\n    \n    num_detections = len(results.boxes)\n    for box in results.boxes:\n        x1, y1, x2, y2 = map(int, box.xyxy[0])\n        conf = float(box.conf[0])\n        cls = int(box.cls[0])\n        name = best_model.names[cls]\n        \n        detection_stats[name] += 1\n        detection_stats['total'] += 1\n        \n        color = colors[name]\n        cv2.rectangle(img_rgb, (x1, y1), (x2, y2), color, 3)\n        \n        label = f\"{name}: {conf:.2f}\"\n        (label_w, label_h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)\n        cv2.rectangle(img_rgb, (x1, y1 - label_h - 10), (x1 + label_w, y1), color, -1)\n        cv2.putText(img_rgb, label, (x1, y1 - 5),\n                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n    \n    axes[idx].imshow(img_rgb)\n    axes[idx].set_title(f'Test {idx+1} | Det: {num_detections}', \n                       fontsize=11, fontweight='bold')\n    axes[idx].axis('off')\n\nplt.suptitle('Test Predictions (Conf ‚â• 0.25)', fontsize=18, fontweight='bold')\nplt.tight_layout()\nplt.show()\n\nprint(\"\\nüìä Detection Statistics:\")\nprint(f\"  Total:  {detection_stats['total']}\")\nprint(f\"  Birds:  {detection_stats['bird']} ({detection_stats['bird']/max(detection_stats['total'],1)*100:.1f}%)\")\nprint(f\"  Drones: {detection_stats['drone']} ({detection_stats['drone']/max(detection_stats['total'],1)*100:.1f}%)\")\nprint(\"=\"*70)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"\\nüìà CONFIDENCE SCORE ANALYSIS\")\nprint(\"=\"*70)\n\nall_test_images = list(test_img_dir.glob('*.jpg'))\nif len(all_test_images) == 0:\n    all_test_images = list(test_img_dir.glob('*.png'))\n\nbird_confidences = []\ndrone_confidences = []\n\nfor img_path in all_test_images:\n    results = best_model.predict(str(img_path), conf=0.1, verbose=False)[0]\n    for box in results.boxes:\n        conf = float(box.conf[0])\n        cls = int(box.cls[0])\n        name = best_model.names[cls]\n        \n        if name == 'bird':\n            bird_confidences.append(conf)\n        else:\n            drone_confidences.append(conf)\n\n# Visualize\nfig, axes = plt.subplots(1, 3, figsize=(20, 5))\n\n# Histogram\naxes[0].hist(bird_confidences, bins=20, alpha=0.7, label='Bird', \n            color='green', edgecolor='black')\naxes[0].hist(drone_confidences, bins=20, alpha=0.7, label='Drone', \n            color='red', edgecolor='black')\naxes[0].set_xlabel('Confidence Score', fontsize=12, fontweight='bold')\naxes[0].set_ylabel('Frequency', fontsize=12, fontweight='bold')\naxes[0].set_title('Distribution', fontsize=14, fontweight='bold')\naxes[0].legend(fontsize=11)\naxes[0].grid(alpha=0.3)\n\n# Box plot\naxes[1].boxplot([bird_confidences, drone_confidences], \n               labels=['Bird', 'Drone'],\n               patch_artist=True,\n               boxprops=dict(facecolor='lightblue', alpha=0.7),\n               medianprops=dict(color='red', linewidth=2))\naxes[1].set_ylabel('Confidence Score', fontsize=12, fontweight='bold')\naxes[1].set_title('Statistics', fontsize=14, fontweight='bold')\naxes[1].grid(alpha=0.3, axis='y')\n\n# Comparison\nx = np.arange(3)\nwidth = 0.35\naxes[2].bar(x - width/2, [np.mean(bird_confidences), np.median(bird_confidences), np.std(bird_confidences)], \n           width, label='Bird', color='green', alpha=0.7)\naxes[2].bar(x + width/2, [np.mean(drone_confidences), np.median(drone_confidences), np.std(drone_confidences)], \n           width, label='Drone', color='red', alpha=0.7)\naxes[2].set_ylabel('Score', fontsize=12, fontweight='bold')\naxes[2].set_title('Comparison', fontsize=14, fontweight='bold')\naxes[2].set_xticks(x)\naxes[2].set_xticklabels(['Mean', 'Median', 'Std'])\naxes[2].legend()\naxes[2].grid(alpha=0.3, axis='y')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\nüìä Statistics:\")\nprint(f\"  Bird:  Mean={np.mean(bird_confidences):.4f}, Median={np.median(bird_confidences):.4f}, Std={np.std(bird_confidences):.4f}\")\nprint(f\"  Drone: Mean={np.mean(drone_confidences):.4f}, Median={np.median(drone_confidences):.4f}, Std={np.std(drone_confidences):.4f}\")\nprint(\"=\"*70)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"\\nüöÄ QUICK INFERENCE FUNCTION\")\nprint(\"=\"*70)\n\ndef quick_predict(image_path, confidence=0.25):\n    \"\"\"Quick prediction on single image\"\"\"\n    results = best_model.predict(image_path, conf=confidence, verbose=False)[0]\n    \n    img = cv2.imread(str(image_path))\n    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    \n    colors = {'bird': (0, 255, 0), 'drone': (255, 0, 0)}\n    \n    for box in results.boxes:\n        x1, y1, x2, y2 = map(int, box.xyxy[0])\n        conf = float(box.conf[0])\n        cls = int(box.cls[0])\n        name = best_model.names[cls]\n        \n        color = colors[name]\n        cv2.rectangle(img_rgb, (x1, y1), (x2, y2), color, 3)\n        cv2.putText(img_rgb, f\"{name}: {conf:.2f}\", (x1, y1-10),\n                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)\n    \n    plt.figure(figsize=(12, 8))\n    plt.imshow(img_rgb)\n    plt.axis('off')\n    plt.title(f'Detections: {len(results.boxes)}', fontsize=14, fontweight='bold')\n    plt.tight_layout()\n    plt.show()\n    \n    print(f\"\\nDetected {len(results.boxes)} objects:\")\n    for box in results.boxes:\n        print(f\"  ‚Ä¢ {best_model.names[int(box.cls[0])]}: {float(box.conf[0]):.3f}\")\n\nprint(\"‚úÖ Function ready! Usage: quick_predict('/path/to/image.jpg')\")\n\n# Demo\ndemo_img = list(test_img_dir.glob('*.jpg'))[0]\nprint(f\"\\nüéØ Demo on: {demo_img.name}\")\nquick_predict(str(demo_img))\nprint(\"=\"*70)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"\\nüì¶ EXPORTING MODELS\")\nprint(\"=\"*70)\n\n# Export ONNX\nprint(\"Exporting to ONNX...\")\nbest_model.export(format='onnx', imgsz=640)\n\n# Copy files\nshutil.copy('/kaggle/working/bird_drone_s/weights/best.pt',  # ‚¨ÜÔ∏è Changed path\n            '/kaggle/working/best_bird_drone.pt')\nshutil.copy('/kaggle/working/bird_drone_s/weights/best.onnx',  # ‚¨ÜÔ∏è Changed path\n            '/kaggle/working/best_bird_drone.onnx')\n\nprint(\"\\n‚úÖ Files exported:\")\nfor file in ['best_bird_drone.pt', 'best_bird_drone.onnx']:\n    path = f'/kaggle/working/{file}'\n    size = os.path.getsize(path) / (1024*1024)\n    print(f\"  üìÑ {file:<25} {size:>6.2f} MB\")\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"üéâ COMPLETE!\")\nprint(\"=\"*70)\nprint(f\"  mAP@0.5:     {metrics.box.map50:.4f}\")\nprint(f\"  mAP@0.5:0.95: {metrics.box.map:.4f}\")\nprint(f\"  Precision:   {metrics.box.mp:.4f}\")\nprint(f\"  Recall:      {metrics.box.mr:.4f}\")\nprint(\"\\nüì• Download: best_bird_drone.pt & best_bird_drone.onnx\")\nprint(\"=\"*70)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}